import openai
import json
import re
import base64
from typing import Dict, Any, List, Optional
import io
from PIL import Image
from utils import api_retrier
import os

class OpenAIHandler:
    """
    Má»™t class "adapter" Ä‘á»ƒ Ä‘Ã³ng gÃ³i táº¥t cáº£ cÃ¡c lá»‡nh gá»i API Ä‘áº¿n OpenAI.
    Che giáº¥u sá»± phá»©c táº¡p cá»§a viá»‡c gá»i API vÃ  cung cáº¥p cÃ¡c phÆ°Æ¡ng thá»©c
    rÃµ rÃ ng cho cÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ (phÃ¢n tÃ­ch, VQA, etc.).
    """
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        print(f"--- ðŸ¤– Khá»Ÿi táº¡o OpenAI Handler vá»›i model máº·c Ä‘á»‹nh: {model} ---")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        self.vision_model = "gpt-4o"
        
    @api_retrier(max_retries=2, initial_delay=1)
    def check_api_health(self) -> bool:
        print("--- ðŸ©º Äang thá»±c hiá»‡n kiá»ƒm tra tráº¡ng thÃ¡i API OpenAI... ---")
        try:
            self.client.embeddings.create(input="kiá»ƒm tra", model="text-embedding-3-small")
            print("--- âœ… Tráº¡ng thÃ¡i API OpenAI: OK ---")
            return True
        except openai.AuthenticationError as e:
            print(f"--- âŒ Lá»—i OpenAI API: Authentication Error. API Key cÃ³ thá»ƒ khÃ´ng há»£p lá»‡. Lá»—i: {e} ---")
            return False
        except Exception as e:
            print(f"--- âŒ Lá»—i OpenAI API: KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n OpenAI. Lá»—i: {e} ---")
            return False

    @api_retrier(max_retries=3, initial_delay=2)
    def _openai_vision_call(self, messages: List[Dict], is_json: bool = True, is_vision: bool = False) -> str:
        model_to_use = self.vision_model if is_vision else self.model
        response_format = {"type": "json_object"} if is_json else {"type": "text"}
        
        response = self.client.chat.completions.create(
            model=model_to_use, messages=messages, response_format=response_format,
            temperature=0.1, max_tokens=1024
        )
        
        if response.choices and response.choices[0].message:
            content = response.choices[0].message.content
            return content if content is not None else "" 
        
        return ""

    def _preprocess_and_encode_image(
        self, 
        image_path: str,
        quality: int = 95 
    ) -> str:
        """
        Chuáº©n hÃ³a Ä‘á»‹nh dáº¡ng áº£nh (sang RGB) vÃ  mÃ£ hÃ³a sang Base64.
        *** KHÃ”NG THAY Äá»”I KÃCH THÆ¯á»šC áº¢NH ***
        """
        try:
            with Image.open(image_path) as img:
                
                if img.mode != 'RGB':
                    print(f"   -> Chuáº©n hÃ³a áº£nh '{os.path.basename(image_path)}' tá»« mode '{img.mode}' sang 'RGB'.")
                    img = img.convert('RGB')

                buffer = io.BytesIO()
                img.save(buffer, format="JPEG", quality=quality)
                img_bytes = buffer.getvalue()
                
                return base64.b64encode(img_bytes).decode('utf-8')

        except FileNotFoundError:
            print(f"--- âš ï¸ Lá»—i khi xá»­ lÃ½ áº£nh: File khÃ´ng tá»“n táº¡i táº¡i '{image_path}' ---")
            return ""
        except Exception as e:
            print(f"--- âš ï¸ Lá»—i khi xá»­ lÃ½ áº£nh {image_path}: {e} ---")
            return ""

    def perform_vqa(self, image_path: str, question: str, context_text: Optional[str] = None) -> Dict[str, any]:
        """
        Thá»±c hiá»‡n VQA sá»­ dá»¥ng GPT-4o, cÃ³ thá»ƒ nháº­n thÃªm bá»‘i cáº£nh tá»« transcript.
        *** PHIÃŠN Báº¢N CÃ“ Xá»¬ LÃ Lá»–I Tá»T HÆ N VÃ€ Bá»I Cáº¢NH Má»ž Rá»˜NG ***
        """
        base64_image = self._preprocess_and_encode_image(image_path)
        if not base64_image:
            return {"answer": "Lá»—i: KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh", "confidence": 0.0}

        
        context_prompt_part = ""
        has_context = False
        if context_text and context_text.strip():
            has_context = True
            truncated_context = (context_text[:500] + '...') if len(context_text) > 503 else context_text
            context_prompt_part = f"""
        **Additional Context from Transcript (What was said around this moment):**
        ---
        "{truncated_context}"
        ---
        """
        
        if has_context:
            print(f"   -> ðŸ§  Thá»±c hiá»‡n VQA vá»›i Context: '{question}'")
        
        prompt = f"""
        Analyze the image and use the provided transcript context (if any) to answer the question in Vietnamese.
        Return a JSON object with two keys: "answer" (string) and "confidence" (float).
        {context_prompt_part}
        Question: "{question}"
        """
        
        messages = [
            {"role": "user", "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
            ]}
        ]

        try:
            response_content = self._openai_vision_call(messages, is_json=True, is_vision=True)
            
            if not response_content:
                print("--- âš ï¸ OpenAI VQA khÃ´ng tráº£ vá» ná»™i dung. ---")
                return {"answer": "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh", "confidence": 0.1}

            result = json.loads(response_content)
            return {
                "answer": result.get("answer", "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i"),
                "confidence": float(result.get("confidence", 0.5))
            }
        except (json.JSONDecodeError, TypeError) as e:
            print(f"Lá»—i OpenAI perform_vqa (JSON parsing): {e}. Response nháº­n Ä‘Æ°á»£c: '{response_content}'")
            return {"answer": "Lá»—i Ä‘á»‹nh dáº¡ng pháº£n há»“i", "confidence": 0.0}
        except Exception as e:
            print(f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong OpenAI perform_vqa: {e}")
            return {"answer": "Lá»—i xá»­ lÃ½ VQA", "confidence": 0.0}

    def decompose_trake_query(self, query: str) -> List[str]:
        prompt = f"""
        Decompose the Vietnamese query...
        ...
        """
        try:
            response_content = self._openai_vision_call([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            if isinstance(result, list):
                return result
            return [query]
        except Exception as e:
            print(f"Lá»—i OpenAI decompose_trake_query: {e}")
            return [query]