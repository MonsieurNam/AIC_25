# ==============================================================================
# SEMANTIC SEARCHER - PHIÃŠN Báº¢N V5 (Tá»I Æ¯U HÃ“A & NÃ‚NG Cáº¤P Tá»ª Báº¢N Gá»C)
# ==============================================================================
import os
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, util
import numpy as np
import json
import re
import torch
from tqdm import tqdm
from typing import Dict, List, Optional, Any
from utils.cache_manager import ObjectVectorCache
from utils.spatial_engine import is_above, is_below, is_between, is_behind, is_inside, is_next_to, is_on
from utils.image_cropper import crop_image_by_box
from search_core.basic_searcher import BasicSearcher

class SemanticSearcher:
    def __init__(self, basic_searcher, rerank_model, device="cuda"):
        print("--- ğŸ§  Khá»Ÿi táº¡o SemanticSearcher (Reranking Engine - Phoenix Edition) ---")
        self.basic_searcher = basic_searcher
        self.model = rerank_model
        self.device = device
        
        # --- Táº¢I "Há»’ Dá»® LIá»†U OBJECT" ---
        self.master_object_df = None
        object_data_path = "/kaggle/input/stage1/master_object_data.parquet"
        if os.path.exists(object_data_path):
            print(f"   -> Äang táº£i Há»“ Dá»¯ liá»‡u Object tá»«: {object_data_path}")
            self.master_object_df = pd.read_parquet(object_data_path)
            # Tá»‘i Æ°u hÃ³a: Set index Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ truy váº¥n sau nÃ y
            self.master_object_df.set_index('keyframe_id', inplace=True)
            print(f"--- âœ… Táº£i thÃ nh cÃ´ng vÃ  láº­p chá»‰ má»¥c cho {len(self.master_object_df)} object. ---")
        else:
            print("--- âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y master_object_data.parquet. Bá»™ lá»c khÃ´ng gian sáº½ bá»‹ vÃ´ hiá»‡u hÃ³a. ---")
            
        # --- TRANG Bá»Š CÃ”NG Cá»¤ CHO Táº¦NG 3 ---
        print("--- ğŸ”¬ Trang bá»‹ cÃ´ng cá»¥ XÃ¡c thá»±c Chi tiáº¿t... ---")
        # Láº¥y quyá»n truy cáº­p vÃ o CLIP model vÃ  processor tá»« BasicSearcher
        self.clip_model = basic_searcher.model
        # self.clip_processor = basic_searcher.processor
        # Khá»Ÿi táº¡o NgÃ¢n hÃ ng Vector Linh hoáº¡t
        self.object_vector_cache = ObjectVectorCache()
        print("--- âœ… Sáºµn sÃ ng hoáº¡t Ä‘á»™ng vá»›i bá»™ nhá»› cache. ---")
            
    def _apply_spatial_filter(self, 
                              candidates: List[Dict], 
                              spatial_rules: List[Dict], 
                              precomputed_analysis: Dict[str, Any]
                             ) -> List[Dict]:
        """
        Ãp dá»¥ng cÃ¡c quy táº¯c khÃ´ng gian Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm 'spatial_score'.
        PHIÃŠN Báº¢N NÃ‚NG Cáº¤P Dá»°A TRÃŠN CODE Gá»C: Sá»­ dá»¥ng cÆ¡ cháº¿ "Cháº¥m Ä‘iá»ƒm Má»m" (Soft Scoring).
        """
        grounding_map = precomputed_analysis.get('grounding_map', {})
        if not spatial_rules or self.master_object_df is None or self.master_object_df.empty:
            for cand in candidates:
                cand['scores']['spatial_score'] = 1.0
            return candidates

        print(f"--- ğŸ“ Ãp dá»¥ng {len(spatial_rules)} Quy táº¯c KhÃ´ng gian (Cháº¿ Ä‘á»™ Cháº¥m Ä‘iá»ƒm Má»m)... ---")
        
        candidate_ids = [c['keyframe_id'] for c in candidates]
        try:
            relevant_objects_df = self.master_object_df.loc[self.master_object_df.index.isin(candidate_ids)]
        except KeyError:
            relevant_objects_df = pd.DataFrame()

        if relevant_objects_df.empty:
            for cand in candidates:
                cand['scores']['spatial_score'] = 0.0
            return candidates

        for cand in candidates:
            keyframe_objects = relevant_objects_df[relevant_objects_df.index == cand['keyframe_id']]
            if keyframe_objects.empty:
                cand['scores']['spatial_score'] = 0.0
                continue
            
            keyframe_objects_lower = keyframe_objects.copy()
            keyframe_objects_lower['object_label'] = keyframe_objects_lower['object_label'].str.lower()
            
            total_rules = len(spatial_rules)
            # âœ… THAY Äá»”I 1: Chuyá»ƒn sang float Ä‘á»ƒ cÃ³ thá»ƒ cá»™ng Ä‘iá»ƒm láº»
            total_satisfied_score = 0.0
            
            is_debug_candidate = cand['keyframe_id'] in [c['keyframe_id'] for c in candidates[:5]]
            if is_debug_candidate:
                print(f"\n--- DEBUG: PhÃ¢n tÃ­ch khÃ´ng gian cho Keyframe: {cand['keyframe_id']} ---")

            for rule in spatial_rules:
                entity_original = rule.get('entity', '').replace('_', ' ')
                relation = rule.get('relation')
                targets_original = [t.replace('_', ' ') for t in rule.get('targets', [])]
                
                entity_grounded = grounding_map.get(entity_original, entity_original).lower()
                targets_grounded = [grounding_map.get(t, t).lower() for t in targets_original]
                
                if is_debug_candidate:
                    print(f"  - Rule: {rule.get('entity')} {relation} {rule.get('targets')}")
                    print(f"    -> Grounded: '{entity_grounded}' vs {targets_grounded}")

                # --- âœ… Báº®T Äáº¦U LOGIC NÃ‚NG Cáº¤P ---
                
                # 1. TÃ¬m bounding box cho Táº¤T Cáº¢ cÃ¡c Ä‘á»‘i tÆ°á»£ng trong quy táº¯c
                entity_boxes = keyframe_objects_lower[keyframe_objects_lower['object_label'] == entity_grounded]['bounding_box'].tolist()
                target_boxes_lists = [keyframe_objects_lower[keyframe_objects_lower['object_label'] == label]['bounding_box'].tolist() for label in targets_grounded]

                if is_debug_candidate:
                    print(f"    -> TÃ¬m tháº¥y: '{entity_grounded}' ({len(entity_boxes)} box), Targets ({[len(boxes) for boxes in target_boxes_lists]} boxes)")
                
                # 2. Kiá»ƒm tra xem cÃ³ Ä‘á»§ Ä‘á»‘i tÆ°á»£ng Ä‘á»ƒ xÃ¡c minh quan há»‡ khÃ´ng gian hay khÃ´ng
                can_verify_relation = (len(entity_boxes) > 0) and all(len(boxes) > 0 for boxes in target_boxes_lists)
                
                rule_satisfied = False
                if can_verify_relation:
                    # Náº¿u cÃ³ Ä‘á»§ Ä‘á»‘i tÆ°á»£ng, tiáº¿n hÃ nh kiá»ƒm tra quan há»‡ khÃ´ng gian nhÆ° code gá»‘c
                    for entity_box in entity_boxes:
                        if rule_satisfied: break
                        
                        # Khá»‘i logic Ä‘iá»u phá»‘i quan há»‡ (giá»¯ nguyÃªn)
                        if relation == 'is_between' and len(target_boxes_lists) == 2:
                            target_pairs = [(b1, b2) for b1 in target_boxes_lists[0] for b2 in target_boxes_lists[1]]
                            for target1_box, target2_box in target_pairs:
                                if np.array_equal(target1_box, target2_box): continue
                                if is_between(entity_box, target1_box, target2_box):
                                    rule_satisfied = True; break
                        
                        elif len(target_boxes_lists) == 1:
                            relation_function = {
                                'is_behind': is_behind, 'is_on': is_on, 'is_above': is_above,
                                'is_below': is_below, 'is_next_to': is_next_to, 'is_inside': is_inside
                            }.get(relation)
                            
                            if relation_function:
                                for target_box in target_boxes_lists[0]:
                                    if relation_function(entity_box, target_box):
                                        rule_satisfied = True; break
                
                # 3. TÃ­nh Ä‘iá»ƒm cuá»‘i cÃ¹ng cho quy táº¯c nÃ y theo cÆ¡ cháº¿ "Má»m"
                if rule_satisfied:
                    # ThÆ°á»Ÿng Ä‘iá»ƒm tá»‘i Ä‘a náº¿u cáº£ quan há»‡ khÃ´ng gian Ä‘á»u Ä‘Ãºng
                    total_satisfied_score += 1.0
                    if is_debug_candidate:
                        print(f"    -> âœ… QUY Táº®C ÄÆ¯á»¢C THá»A MÃƒN HOÃ€N TOÃ€N! (1.0 Ä‘iá»ƒm)")
                else:
                    # Náº¿u quan há»‡ khÃ´ng gian khÃ´ng Ä‘Ãºng HOáº¶C khÃ´ng thá»ƒ xÃ¡c minh (do thiáº¿u Ä‘á»‘i tÆ°á»£ng),
                    # chÃºng ta váº«n thÆ°á»Ÿng Ä‘iá»ƒm náº¿u má»™t pháº§n Ä‘á»‘i tÆ°á»£ng tá»“n táº¡i.
                    all_entities_in_rule = [entity_grounded] + targets_grounded
                    found_entities_count = (1 if entity_boxes else 0) + sum(1 for boxes in target_boxes_lists if boxes)
                    existence_score = found_entities_count / len(all_entities_in_rule) if all_entities_in_rule else 0
                    
                    # ThÆ°á»Ÿng 50% cá»§a Ä‘iá»ƒm tá»“n táº¡i.
                    # VÃ­ dá»¥: náº¿u tÃ¬m tháº¥y 2/3 Ä‘á»‘i tÆ°á»£ng, Ä‘iá»ƒm thÆ°á»Ÿng lÃ  0.5 * (2/3) = 0.33
                    partial_score = 0.5 * existence_score
                    total_satisfied_score += partial_score
                    if is_debug_candidate and partial_score > 0:
                        print(f"    -> âš ï¸  QUY Táº®C KHá»šP Má»˜T PHáº¦N (do Ä‘á»‘i tÆ°á»£ng tá»“n táº¡i). ({partial_score:.2f} Ä‘iá»ƒm)")
            
            # âœ… THAY Äá»”I 2: TÃ­nh Ä‘iá»ƒm trung bÃ¬nh cuá»‘i cÃ¹ng tá»« tá»•ng Ä‘iá»ƒm Ä‘Ã£ tÃ­ch lÅ©y
            cand['scores']['spatial_score'] = total_satisfied_score / total_rules if total_rules > 0 else 1.0
        
        print("    -> VÃ­ dá»¥ Ä‘iá»ƒm khÃ´ng gian (Cháº¥m Ä‘iá»ƒm Má»m):", {c['keyframe_id']: f"{c['scores'].get('spatial_score', 0):.2f}" for c in candidates[:5]})
        return candidates
    
    def _apply_fine_grained_filter(self, candidates: List[Dict], verification_rules: List[Dict]) -> List[Dict]:
        """
        Sá»­ dá»¥ng CLIP trÃªn cÃ¡c vÃ¹ng áº£nh Ä‘Ã£ crop Ä‘á»ƒ xÃ¡c thá»±c cÃ¡c chi tiáº¿t nhá».
        """
        if not verification_rules or self.master_object_df is None or self.master_object_df.empty:
            for cand in candidates:
                cand['scores']['fine_grained_score'] = 1.0
            return candidates

        print(f"--- ğŸ”¬ Ãp dá»¥ng {len(verification_rules)} Quy táº¯c XÃ¡c thá»±c Chi tiáº¿t...")
        
        # Chá»‰ xá»­ lÃ½ trÃªn top 50 á»©ng viÃªn Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian, sá»‘ cÃ²n láº¡i nháº­n Ä‘iá»ƒm máº·c Ä‘á»‹nh
        top_candidates = candidates[:50]
        
        # Encode táº¥t cáº£ cÃ¡c mÃ´ táº£ text má»™t láº§n duy nháº¥t
        detailed_descriptions = [rule['detailed_description'] for rule in verification_rules]
        with torch.no_grad():
            text_features = self.clip_model.encode(detailed_descriptions, convert_to_tensor=True, device=self.device)
            text_features /= text_features.norm(dim=-1, keepdim=True)

        for cand in tqdm(top_candidates, desc="XÃ¡c thá»±c chi tiáº¿t (soi kÃ­nh hiá»ƒn vi)"):
            keyframe_id = cand['keyframe_id']
            keyframe_objects = self.master_object_df.loc[self.master_object_df.index == keyframe_id]
            
            if keyframe_objects.empty:
                cand['scores']['fine_grained_score'] = 0.0
                continue
            
            total_score = 0.0
            for i, rule in enumerate(verification_rules):
                object_vector = None
                target_label = rule['target_entity']
                
                # TÃ¬m object phÃ¹ há»£p nháº¥t trong keyframe (confidence cao nháº¥t)
                possible_objects = keyframe_objects[keyframe_objects['object_label'].str.contains(target_label, case=False)]
                if possible_objects.empty:
                    continue # Bá» qua rule nÃ y náº¿u khÃ´ng cÃ³ object khá»›p

                best_object_series = possible_objects.sort_values(by='confidence_score', ascending=False).iloc[0]
    
                # Láº¥y giÃ¡ trá»‹ má»™t cÃ¡ch an toÃ n vÃ  kiá»ƒm tra kiá»ƒu
                confidence_value = best_object_series.get('confidence_score')
                bounding_box_value = best_object_series.get('bounding_box')

                # Kiá»ƒm tra kiá»ƒu dá»¯ liá»‡u trÆ°á»›c khi sá»­ dá»¥ng
                if not isinstance(confidence_value, (int, float)):
                    print(f"--- âš ï¸ WARNING: Kiá»ƒu dá»¯ liá»‡u confidence_score khÃ´ng há»£p lá»‡ ({type(confidence_value)}) cho keyframe {keyframe_id}. Bá» qua rule. ---")
                    continue
                    
                if bounding_box_value is None:
                    continue
                
                # Giá» thÃ¬ chÃºng ta cÃ³ thá»ƒ yÃªn tÃ¢m sá»­ dá»¥ng
                cache_key = f"{keyframe_id}_{target_label}_{confidence_value:.4f}"
                
                # --- Káº¾T THÃšC THAY THáº¾ ---

                if object_vector is None: # Cache miss
                    try:
                        # Ã‰p kiá»ƒu bounding_box thÃ nh list Ä‘á»ƒ Ä‘áº£m báº£o
                        cropped_image = crop_image_by_box(cand['keyframe_path'], list(bounding_box_value))
                        with torch.no_grad():
                            image_features = self.clip_model.encode(cropped_image, convert_to_tensor=True, device=self.device)
                            image_features /= image_features.norm(dim=-1, keepdim=True)
                        
                        object_vector = image_features.cpu().numpy()
                        self.object_vector_cache.set(cache_key, object_vector)
                    except Exception as e:
                        print(f"Lá»—i khi xá»­ lÃ½ áº£nh crop cho {keyframe_id}: {e}")
                        continue
                
                # TÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
                image_tensor = torch.from_numpy(object_vector).to(self.device)
                similarity = util.pytorch_cos_sim(image_tensor, text_features[i].unsqueeze(0))
                total_score += similarity.item()

            cand['scores']['fine_grained_score'] = total_score / len(verification_rules) if verification_rules else 1.0

        # GÃ¡n Ä‘iá»ƒm máº·c Ä‘á»‹nh cho cÃ¡c á»©ng viÃªn khÃ´ng Ä‘Æ°á»£c check
        for cand in candidates[50:]:
            cand['scores']['fine_grained_score'] = 0.5 # Äiá»ƒm trung bÃ¬nh

        return candidates

    def search(self,
               query_text: str,
               top_k_final: int,
               top_k_retrieval: int,
               precomputed_analysis: Dict[str, Any] = None,
               weights: Dict[str, float] = None
              ) -> List[Dict[str, Any]]:
        """
        Thá»±c hiá»‡n tÃ¬m kiáº¿m vÃ  tÃ¡i xáº¿p háº¡ng Ä‘a táº§ng theo kiáº¿n trÃºc PHOENIX.
        Luá»“ng xá»­ lÃ½: Contextual -> Spatial -> Fine-grained Verification.
        """
        print("\n--- ğŸ”± Báº¯t Ä‘áº§u quy trÃ¬nh tÃ¬m kiáº¿m Ä‘a táº§ng PHOENIX... ---")

        # --- BÆ°á»›c 0: Chuáº©n bá»‹ ---
        if precomputed_analysis is None: precomputed_analysis = {}
        # Äáº·t trá»ng sá»‘ máº·c Ä‘á»‹nh vÃ  cho phÃ©p ghi Ä‘Ã¨ tá»« UI
        final_weights = {
            'w_clip': 0.2, 
            'w_semantic': 0.3, 
            'w_spatial': 0.25, 
            'w_fine_grained': 0.25, 
            **(weights or {})
        }
        print(f"    -> Trá»ng sá»‘ há»a lá»±c: {final_weights}")

        # --- Táº¦NG 1: Bá»˜ Lá»ŒC NGá»® Cáº¢NH (Láº¥y á»©ng viÃªn thÃ´ báº±ng CLIP toÃ n cá»¥c) ---
        print(f"--- Táº§ng 1: Láº¥y Top-{top_k_retrieval} á»©ng viÃªn theo Ngá»¯ cáº£nh... ---")
        candidates = self.basic_searcher.search(query_text, top_k=top_k_retrieval)
        if not candidates:
            print("--- â›” KhÃ´ng tÃ¬m tháº¥y á»©ng viÃªn nÃ o á»Ÿ Táº§ng 1. Dá»«ng tÃ¬m kiáº¿m. ---")
            return []
        print(f"    -> TÃ¬m tháº¥y {len(candidates)} á»©ng viÃªn tiá»m nÄƒng.")
        
        # Khá»Ÿi táº¡o cáº¥u trÃºc Ä‘iá»ƒm cho má»—i á»©ng viÃªn
        for cand in candidates:
            cand['scores'] = {'clip_score': cand.get('clip_score', 0.0)}

        # --- RERANKING NGá»® NGHÄ¨A (Tinh chá»‰nh Ä‘iá»ƒm ngá»¯ cáº£nh báº±ng Bi-Encoder) ---
        # (Pháº§n nÃ y báº¡n cáº§n Ä‘áº£m báº£o logic rerank_batch cá»§a mÃ¬nh Ä‘Æ°á»£c tÃ­ch há»£p á»Ÿ Ä‘Ã¢y)
        # Giáº£ sá»­ sau bÆ°á»›c nÃ y, 'semantic_score' Ä‘Æ°á»£c thÃªm vÃ o
        print("--- Táº§ng 1.5: Tinh chá»‰nh Ä‘iá»ƒm Ngá»¯ nghÄ©a báº±ng Bi-Encoder... ---")
        # VÃ­ dá»¥:
        # candidates = self.rerank_with_bi_encoder(candidates, query_text)
        # Táº¡m thá»i gÃ¡n Ä‘iá»ƒm giáº£ Ä‘á»‹nh Ä‘á»ƒ code cháº¡y Ä‘Æ°á»£c
        for cand in candidates:
             cand['scores']['semantic_score'] = cand['scores']['clip_score'] # Táº¡m thá»i gÃ¡n báº±ng Ä‘iá»ƒm clip
        print("    -> HoÃ n táº¥t tinh chá»‰nh Ä‘iá»ƒm ngá»¯ nghÄ©a.")


        # --- Táº¦NG 2: Bá»˜ Lá»ŒC QUAN Há»† KHÃ”NG GIAN ---
        spatial_rules = precomputed_analysis.get('spatial_rules', [])
        
        candidates_after_spatial = self._apply_spatial_filter(
            candidates=candidates, 
            spatial_rules=spatial_rules, 
            precomputed_analysis=precomputed_analysis
        )

        # --- Táº¦NG 3: Bá»˜ Lá»ŒC XÃC THá»°C CHI TIáº¾T ---
        verification_rules = precomputed_analysis.get('fine_grained_verification', [])
        
        # Sáº¯p xáº¿p láº¡i trÆ°á»›c khi Ä‘Æ°a vÃ o Táº§ng 3 Ä‘á»ƒ Ä‘áº£m báº£o chá»‰ "soi" nhá»¯ng á»©ng viÃªn tá»‘t nháº¥t
        # TÃ­nh Ä‘iá»ƒm táº¡m thá»i sau Táº§ng 2
        for cand in candidates_after_spatial:
            s = cand['scores']
            cand['temp_score'] = (
                final_weights['w_clip'] * s.get('clip_score', 0.0) +
                final_weights['w_semantic'] * s.get('semantic_score', 0.0) +
                final_weights['w_spatial'] * s.get('spatial_score', 0.5)
            )
        
        sorted_before_fine_grained = sorted(candidates_after_spatial, key=lambda x: x.get('temp_score', 0.0), reverse=True)

        candidates_after_fine_grained = self._apply_fine_grained_filter(sorted_before_fine_grained, verification_rules)


        # --- BÆ¯á»šC CUá»I: TÃNH ÄIá»‚M Tá»”NG Há»¢P VÃ€ Sáº®P Xáº¾P ---
        print("--- ğŸ¯ TÃ­nh toÃ¡n Ä‘iá»ƒm há»a lá»±c cuá»‘i cÃ¹ng vÃ  sáº¯p xáº¿p... ---")
        for cand in candidates_after_fine_grained:
            scores = cand['scores']
            
            # CÃ´ng thá»©c Ä‘iá»ƒm hoÃ n chá»‰nh
            final_score = (
                final_weights['w_clip'] * scores.get('clip_score', 0.0) +
                final_weights['w_semantic'] * scores.get('semantic_score', 0.0) +
                final_weights['w_spatial'] * scores.get('spatial_score', 0.5) + # DÃ¹ng 0.5 lÃ m Ä‘iá»ƒm máº·c Ä‘á»‹nh náº¿u cÃ³ lá»—i
                final_weights['w_fine_grained'] * scores.get('fine_grained_score', 0.5) # DÃ¹ng 0.5 lÃ m Ä‘iá»ƒm máº·c Ä‘á»‹nh
            )
            cand['final_score'] = final_score

        # Sáº¯p xáº¿p láº¡i láº§n cuá»‘i cÃ¹ng dá»±a trÃªn Ä‘iá»ƒm tá»•ng há»£p
        final_sorted_candidates = sorted(candidates_after_fine_grained, key=lambda x: x.get('final_score', 0.0), reverse=True)
        
        print(f"--- âœ… Quy trÃ¬nh PHOENIX hoÃ n táº¥t. Tráº£ vá» Top-{top_k_final} káº¿t quáº£. ---")
        
        # In ra 3 káº¿t quáº£ Ä‘áº§u tiÃªn Ä‘á»ƒ debug
        for i, cand in enumerate(final_sorted_candidates[:3]):
            print(f"  Top {i+1}: {cand['keyframe_id']} | Score: {cand['final_score']:.4f} | Scores: {cand['scores']}")

        return final_sorted_candidates[:top_k_final]