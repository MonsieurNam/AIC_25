# /search_core/basic_searcher.py

import faiss
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List, Dict

class BasicSearcher:
    """
    BasicSearcher: ƒê·ªông c∆° Retrieval N·ªÅn t·∫£ng (Core Retrieval Engine).
    
    Ch·ªãu tr√°ch nhi·ªám cho t·∫ßng t√¨m ki·∫øm ƒë·∫ßu ti√™n v√† nhanh nh·∫•t.
    - T·∫£i v√† qu·∫£n l√Ω FAISS index ƒë·ªÉ t√¨m ki·∫øm vector t·ªëc ƒë·ªô cao.
    - T·∫£i v√† qu·∫£n l√Ω metadata t∆∞∆°ng ·ª©ng.
    - T·∫£i v√† qu·∫£n l√Ω model CLIP ƒë·ªÉ m√£ h√≥a c√°c truy v·∫•n vƒÉn b·∫£n th√†nh vector.
    
    Ki·∫øn tr√∫c PHOENIX.
    """
    def __init__(self, 
                 faiss_index_path: str, 
                 metadata_path: str, 
                 clip_model_name: str = 'clip-ViT-B-32',
                 device: str = "cuda"):
        """
        Kh·ªüi t·∫°o BasicSearcher.
        T·∫£i t·∫•t c·∫£ c√°c t√†i nguy√™n c·∫ßn thi·∫øt v√†o b·ªô nh·ªõ.
        """
        print("--- üîç Kh·ªüi t·∫°o BasicSearcher (Core Retrieval Engine - Phoenix Edition)... ---")
        self.device = device
        
        try:
            # --- 1. T·∫£i FAISS Index ---
            print(f"   -> ƒêang t·∫£i FAISS index t·ª´: {faiss_index_path}")
            self.index = faiss.read_index(faiss_index_path)
            
            # --- 2. T·∫£i Metadata ---
            print(f"   -> ƒêang t·∫£i metadata t·ª´: {metadata_path}")
            # Ch·ªâ t·∫£i c√°c c·ªôt c·∫ßn thi·∫øt ƒë·ªÉ ti·∫øt ki·ªám RAM t·ªëi ƒëa
            self.metadata = pd.read_parquet(
                metadata_path, 
                columns=['keyframe_id', 'video_id', 'timestamp', 'keyframe_path']
            )
            print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {self.index.ntotal} vector v√† metadata t∆∞∆°ng ·ª©ng. ---")
            
            # --- 3. T·∫£i CLIP Model ---
            print(f"   -> ƒêang t·∫£i CLIP model: {clip_model_name} l√™n {self.device}")
            # S·ª≠ d·ª•ng SentenceTransformer ƒë·ªÉ c√≥ API ti·ªán l·ª£i cho c·∫£ model v√† processor
            self.model = SentenceTransformer(clip_model_name, device=self.device)
            print("--- ‚úÖ T·∫£i CLIP model th√†nh c√¥ng. BasicSearcher s·∫µn s√†ng ho·∫°t ƒë·ªông! ---")
            
        except FileNotFoundError as e:
            print(f"--- ‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y file c·∫ßn thi·∫øt: {e}. ---")
            print("    -> H√£y ch·∫Øc ch·∫Øn r·∫±ng c√°c ƒë∆∞·ªùng d·∫´n trong config.py l√† ch√≠nh x√°c.")
            raise e
        except Exception as e:
            print(f"--- ‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh khi kh·ªüi t·∫°o BasicSearcher: {e} ---")
            raise e

    def search(self, query_text: str, top_k: int) -> List[Dict]:
        """
        Th·ª±c hi·ªán t√¨m ki·∫øm vector tr√™n FAISS index.

        Args:
            query_text (str): Chu·ªói vƒÉn b·∫£n truy v·∫•n.
            top_k (int): S·ªë l∆∞·ª£ng k·∫øt qu·∫£ g·∫ßn nh·∫•t c·∫ßn t√¨m.

        Returns:
            List[Dict]: M·ªôt danh s√°ch c√°c dictionary, m·ªói c√°i ch·ª©a th√¥ng tin c·ªßa m·ªôt keyframe.
        """
        if not query_text or not query_text.strip():
            return []

        # 1. M√£ h√≥a truy v·∫•n vƒÉn b·∫£n th√†nh vector embedding
        #    S·ª≠ d·ª•ng model ƒë√£ ƒë∆∞·ª£c t·∫£i s·∫µn trong __init__
        query_embedding = self.model.encode(
            query_text, 
            convert_to_tensor=True, 
            device=self.device,
            show_progress_bar=False # T·∫Øt progress bar ƒë·ªÉ log g·ªçn g√†ng h∆°n
        )
        
        # Chuy·ªÉn v·ªÅ numpy v√† reshape ƒë·ªÉ ph√π h·ª£p v·ªõi input c·ªßa FAISS
        query_embedding_np = query_embedding.cpu().numpy().reshape(1, -1)
        
        # 2. Chu·∫©n h√≥a L2 (b·∫Øt bu·ªôc cho t√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng cosine tr√™n FAISS)
        faiss.normalize_L2(query_embedding_np)

        # 3. T√¨m ki·∫øm tr√™n FAISS index
        #    `search` tr·∫£ v·ªÅ (distances, indices)
        distances, indices = self.index.search(query_embedding_np, top_k)
        
        # 4. L·∫•y th√¥ng tin metadata v√† ƒë·ªãnh d·∫°ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
        results = []
        result_indices = indices[0]
        result_distances = distances[0]
        
        for i in range(len(result_indices)):
            idx = result_indices[i]
            
            # L·∫•y th√¥ng tin t·ª´ metadata b·∫±ng index (iloc r·∫•t nhanh)
            meta_info = self.metadata.iloc[idx].to_dict()
            
            # Th√™m ƒëi·ªÉm s·ªë v√† index g·ªëc v√†o k·∫øt qu·∫£
            meta_info['clip_score'] = float(result_distances[i])
            meta_info['original_index'] = int(idx) # D√πng cho MMR
            
            results.append(meta_info)
            
        return results