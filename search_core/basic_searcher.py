# /search_core/basic_searcher.py

import faiss
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List, Dict

class BasicSearcher:
    """
    BasicSearcher: ƒê·ªông c∆° Retrieval N·ªÅn t·∫£ng (Core Retrieval Engine).
    
    Ch·ªãu tr√°ch nhi·ªám cho t·∫ßng t√¨m ki·∫øm ƒë·∫ßu ti√™n v√† nhanh nh·∫•t.
    - T·∫£i v√† qu·∫£n l√Ω FAISS index ƒë·ªÉ t√¨m ki·∫øm vector t·ªëc ƒë·ªô cao.
    - T·∫£i v√† qu·∫£n l√Ω metadata t∆∞∆°ng ·ª©ng.
    - T·∫£i v√† qu·∫£n l√Ω model CLIP ƒë·ªÉ m√£ h√≥a c√°c truy v·∫•n vƒÉn b·∫£n th√†nh vector.
    
    Ki·∫øn tr√∫c PHOENIX.
    """
    def __init__(self, 
                 faiss_index_path: str, 
                 metadata_path: str, 
                 clip_model_name: str = 'clip-ViT-B-32',
                 device: str = "cuda"):
        """
        Kh·ªüi t·∫°o BasicSearcher.
        T·∫£i t·∫•t c·∫£ c√°c t√†i nguy√™n c·∫ßn thi·∫øt v√†o b·ªô nh·ªõ.
        """
        print("--- üîç Kh·ªüi t·∫°o BasicSearcher (Core Retrieval Engine - Phoenix Edition)... ---")
        self.device = device
        try:
            print(f"   -> ƒêang t·∫£i FAISS index t·ª´: {faiss_index_path}")
            self.index = faiss.read_index(faiss_index_path)
            print(f"   -> ƒêang t·∫£i metadata t·ª´: {metadata_path}")
            self.metadata = pd.read_parquet(
                metadata_path, 
                columns=['keyframe_id', 'video_id', 'timestamp', 'keyframe_path']
            )
            print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {self.index.ntotal} vector v√† metadata t∆∞∆°ng ·ª©ng. ---")
            print(f"   -> ƒêang t·∫£i CLIP model: {clip_model_name} l√™n {self.device}")
            self.model = SentenceTransformer(clip_model_name, device=self.device)
            print("--- ‚úÖ T·∫£i CLIP model th√†nh c√¥ng. BasicSearcher s·∫µn s√†ng ho·∫°t ƒë·ªông! ---")
        except FileNotFoundError as e:
            print(f"--- ‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y file c·∫ßn thi·∫øt: {e}. ---")
            print("    -> H√£y ch·∫Øc ch·∫Øn r·∫±ng c√°c ƒë∆∞·ªùng d·∫´n trong config.py l√† ch√≠nh x√°c.")
            raise e
        except Exception as e:
            print(f"--- ‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh khi kh·ªüi t·∫°o BasicSearcher: {e} ---")
            raise e

    def search(self, query_text: str, top_k: int) -> List[Dict]:
        """
        Th·ª±c hi·ªán t√¨m ki·∫øm vector tr√™n FAISS index.

        Args:
            query_text (str): Chu·ªói vƒÉn b·∫£n truy v·∫•n.
            top_k (int): S·ªë l∆∞·ª£ng k·∫øt qu·∫£ g·∫ßn nh·∫•t c·∫ßn t√¨m.

        Returns:
            List[Dict]: M·ªôt danh s√°ch c√°c dictionary, m·ªói c√°i ch·ª©a th√¥ng tin c·ªßa m·ªôt keyframe.
        """
        if not query_text or not query_text.strip():
            return []
        query_embedding = self.model.encode(
            query_text, 
            convert_to_tensor=True, 
            device=self.device,
            show_progress_bar=False 
        )
        query_embedding_np = query_embedding.cpu().numpy().reshape(1, -1)
        faiss.normalize_L2(query_embedding_np)
        distances, indices = self.index.search(query_embedding_np, top_k)
        results = []
        result_indices = indices[0]
        result_distances = distances[0]
        for i in range(len(result_indices)):
            idx = result_indices[i]
            meta_info = self.metadata.iloc[idx].to_dict()
            meta_info['clip_score'] = float(result_distances[i])
            meta_info['original_index'] = int(idx)
            results.append(meta_info)
        return results