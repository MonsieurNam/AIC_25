import faiss
from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
class BasicSearcher:
    def __init__(self, faiss_index_path, metadata_path, clip_model_name='clip-ViT-L-14'):
        """
        Kh·ªüi t·∫°o BasicSearcher - T·∫ßng retrieval n·ªÅn t·∫£ng.
        PHI√äN B·∫¢N N√ÇNG C·∫§P: T·∫£i v√† l∆∞u tr·ªØ model/processor.
        """
        print("--- üîç Kh·ªüi t·∫°o BasicSearcher (Core Retrieval Engine)... ---")
        try:
            print(f"   -> ƒêang t·∫£i FAISS index t·ª´: {faiss_index_path}")
            self.index = faiss.read_index(faiss_index_path)
            print(f"   -> ƒêang t·∫£i metadata t·ª´: {metadata_path}")
            self.metadata = pd.read_parquet(metadata_path, columns=['keyframe_id', 'video_id', 'timestamp', 'keyframe_path', 'video_path'])
            print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {self.index.ntotal} vector v√† metadata. ---")
            
            print(f"   -> ƒêang t·∫£i CLIP model: {clip_model_name}")
            self.model = SentenceTransformer(clip_model_name, device='cuda')
            print("--- ‚úÖ T·∫£i CLIP model th√†nh c√¥ng. ---")
            
        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o BasicSearcher: {e} ---")
            raise e

    def get_all_clip_features(self) -> np.ndarray: # <-- PH∆Ø∆†NG TH·ª®C M·ªöI
        """Tr·∫£ v·ªÅ ma tr·∫≠n NumPy c·ªßa t·∫•t c·∫£ c√°c vector CLIP."""
        return self.clip_features_numpy
    
    def search(self, query_text: str, top_k: int) -> list:
        """
        Th·ª±c hi·ªán t√¨m ki·∫øm vector tr√™n FAISS.
        """
        if not query_text:
            return []

        # 1. M√£ h√≥a query text th√†nh vector s·ª≠ d·ª•ng model ƒë√£ ƒë∆∞·ª£c t·∫£i s·∫µn
        query_embedding = self.model.encode(query_text, convert_to_tensor=True, device=self.device)
        query_embedding = query_embedding.cpu().numpy().reshape(1, -1)
        
        # Chu·∫©n h√≥a L2 (quan tr·ªçng ƒë·ªÉ so s√°nh cosine)
        faiss.normalize_L2(query_embedding)

        # 2. T√¨m ki·∫øm tr√™n FAISS index
        distances, indices = self.index.search(query_embedding, top_k)
        
        # 3. L·∫•y th√¥ng tin metadata v√† tr·∫£ v·ªÅ k·∫øt qu·∫£
        results = []
        for i in range(top_k):
            idx = indices[0][i]
            # L·∫•y th√¥ng tin t·ª´ metadata b·∫±ng index
            meta_info = self.metadata.iloc[idx].to_dict()
            meta_info['clip_score'] = float(distances[0][i])
            # Th√™m index g·ªëc ƒë·ªÉ MMR c√≥ th·ªÉ d√πng n·∫øu c·∫ßn
            meta_info['original_index'] = idx
            results.append(meta_info)
            
        return results