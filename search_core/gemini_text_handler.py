# ==============================================================================
# GEMINI TEXT HANDLER - PHI√äN B·∫¢N CU·ªêI C√ôNG (ENTITY-AWARE)
# File: gemini_text_handler.py
#
# THAY ƒê·ªîI C·ªêT L√ïI:
#   - S·ª≠a ƒë·ªïi SYSTEM_PROMPT ƒë·ªÉ t√≠ch h·ª£p "T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng To√†n c·ª•c",
#     h∆∞·ªõng d·∫´n Gemini ∆∞u ti√™n s·ª≠ d·ª•ng c√°c nh√£n th·ª±c th·ªÉ ƒë√£ bi·∫øt.
#   - T·ªëi ∆∞u h√≥a vi·ªác t·∫°o prompt ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa Semantic Grounding
#     v√† ph√¢n t√≠ch kh√¥ng gian.
# ==============================================================================

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from typing import Dict, Any, List, Set
import json
import re

from utils import api_retrier

class GeminiTextHandler:
    """
    M·ªôt class chuy√™n d·ª•ng ƒë·ªÉ x·ª≠ l√Ω T·∫§T C·∫¢ c√°c t√°c v·ª• li√™n quan ƒë·∫øn vƒÉn b·∫£n
    b·∫±ng API c·ªßa Google Gemini. PHI√äN B·∫¢N N√ÇNG C·∫§P (ENTITY-AWARE).
    """

    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash"):
        """
        Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Text Handler.
        """
        print(f"--- ‚ú® Kh·ªüi t·∫°o Gemini Text Handler v·ªõi model: {model_name} ---")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name)
            self.known_entities_prompt_segment: str = "[]" # M·∫∑c ƒë·ªãnh l√† list r·ªóng d·∫°ng chu·ªói
            
            # --- C·∫•u h√¨nh API call ---
            self.generation_config = {
                "temperature": 0.1,
                "top_p": 0.95,
                "top_k": 64,
                "max_output_tokens": 8192,
                "response_mime_type": "application/json",
            }
            self.safety_settings = {
                'HATE': 'BLOCK_NONE', 'HARASSMENT': 'BLOCK_NONE',
                'SEXUAL': 'BLOCK_NONE', 'DANGEROUS': 'BLOCK_NONE'
            }
            
            # --- X√°c th·ª±c API Key b·∫±ng m·ªôt l·ªánh g·ªçi nh·ªè ---
            print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API Gemini... ---")
            self.model.count_tokens("test") 
            print("--- ‚úÖ Tr·∫°ng th√°i API Gemini: OK ---")

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o Gemini Handler: {e} ---")
            print("    -> Vui l√≤ng ki·ªÉm tra l·∫°i API Key v√† k·∫øt n·ªëi m·∫°ng.")
            raise e

    def _get_system_prompt(self) -> str:
        """
        H√†m t·∫°o ra SYSTEM_PROMPT ƒë·ªông, nh√∫ng danh s√°ch th·ª±c th·ªÉ ƒë√£ bi·∫øt v√†o.
        ƒê√¢y l√† ph·∫ßn n√¢ng c·∫•p c·ªët l√µi ƒë·ªÉ Gemini "nh·∫≠n th·ª©c" ƒë∆∞·ª£c t·ª´ ƒëi·ªÉn c·ªßa h·ªá th·ªëng.
        """
        return f"""
You are a highly precise multimedia scene analyst for a Vietnamese video search engine. Your task is to deconstruct a user's query into a structured, machine-readable JSON object. Your SOLE output must be a single, valid JSON object and nothing else. Adhere strictly to the specified formats and keywords.

**IMPORTANT RULE:** When creating `entity` and `targets` for `spatial_rules`, you MUST prioritize using a label from this list of KNOWN ENTITIES if it is relevant: {self.known_entities_prompt_segment}. This is crucial for the system to understand. For example, if the user mentions a "giant crab symbol" and "building" is in the KNOWN ENTITIES list, you should prefer using "building". If no known entity is a good fit, you may create a new descriptive label.

Analyze the user query to extract three components:
1.  **`search_context` (string):**
    *   This is a conceptual summary. IGNORE specific, verifiable details like exact counts ("three people"), colors ("red shirt"), or text on signs.
    *   FOCUS on the **core activity, environment, and overall theme**.
    *   Good Example: For "a girl in a red dress with a yellow balloon", the context is "a child enjoying an outdoor festival or celebration".

2.  **`spatial_rules` (list of objects):**
    *   Identify ALL explicit spatial relationships.
    *   For each, create an object with `entity`, `relation`, and `targets`.
    *   **`relation` MUST be one of these exact keywords:** `is_between`, `is_behind`, `is_next_to`, `is_above`, `is_below`, `is_on`, `is_inside`.
    *   **`entity` and `targets`**: Use descriptive, snake_cased English labels (e.g., "person_white_shirt", "black_car"). Remember to use labels from the KNOWN ENTITIES list when possible.

3.  **`fine_grained_verification` (list of objects):**
    *   Identify objects with highly specific visual descriptions.
    *   For each, create an object with `target_entity` (the general, common, single-word English class name, e.g., "Bird", "Car") and `detailed_description` (the full descriptive English sentence).

---
**COMPREHENSIVE EXAMPLE:**
User Query: "Find a clip of three people (a woman in a white shirt sitting between two men in black shirts) playing instruments, with a bookshelf behind them."

Your JSON output:
{{
  "search_context": "a group of people playing musical instruments in a cozy, indoor setting like a library or studio",
  "spatial_rules": [
    {{
      "entity": "woman",
      "relation": "is_between",
      "targets": ["man", "man"]
    }},
    {{
      "entity": "bookshelf",
      "relation": "is_behind",
      "targets": ["woman"]
    }}
  ],
  "fine_grained_verification": []
}}
---
Now, analyze the user's query and provide ONLY the JSON output.
"""

    @api_retrier(max_retries=3, initial_delay=1)
    def _gemini_api_call(self, content_list: list) -> genai.GenerativeModel.generate_content:
        """H√†m con ƒë∆∞·ª£c "trang tr√≠", chuy√™n th·ª±c hi·ªán l·ªánh g·ªçi API c·ªßa Gemini."""
        return self.model.generate_content(
            content_list,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings
        )

    def load_known_entities(self, known_entities: Set[str]):
        """
        Chu·∫©n b·ªã v√† cache l·∫°i ph·∫ßn prompt ch·ª©a t·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng.
        Ch·ªâ c·∫ßn g·ªçi m·ªôt l·∫ßn khi MasterSearcher kh·ªüi t·∫°o.
        """
        if not known_entities:
            print("--- ‚ö†Ô∏è T·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng r·ªóng. Semantic Grounding s·∫Ω kh√¥ng ho·∫°t ƒë·ªông t·ªëi ∆∞u. ---")
            return
        
        sorted_entities = sorted(list(known_entities))
        # ƒê·ªãnh d·∫°ng th√†nh chu·ªói JSON ƒë·ªÉ nh√∫ng v√†o prompt
        self.known_entities_prompt_segment = json.dumps(sorted_entities)
        print(f"--- ‚úÖ GeminiTextHandler: ƒê√£ n·∫°p {len(sorted_entities)} th·ª±c th·ªÉ v√†o b·ªô nh·ªõ prompt. ---")

    def analyze_query_fully(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch s√¢u m·ªôt truy v·∫•n, tr√≠ch xu·∫•t ng·ªØ c·∫£nh, ƒë·ªëi t∆∞·ª£ng, v√† c√°c quy t·∫Øc.
        """
        print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n c√≥ c·∫•u tr√∫c b·∫±ng Gemini (Entity-Aware)... ---")
        
        system_prompt = self._get_system_prompt()
        user_prompt = f"User Query: \"{query}\""
        
        try:
            response = self._gemini_api_call([system_prompt, user_prompt])
            raw_response_text = response.text.strip()
            
            try:
                if raw_response_text.startswith("```json"):
                    raw_response_text = raw_response_text[7:-3].strip()
                analysis_json = json.loads(raw_response_text)
                
                # Tr√≠ch xu·∫•t c√°c th·ª±c th·ªÉ c·∫ßn ƒë∆∞·ª£c "grounding" sau n√†y
                entities_to_ground = set()
                if 'spatial_rules' in analysis_json and isinstance(analysis_json['spatial_rules'], list):
                    for rule in analysis_json['spatial_rules']:
                        if 'entity' in rule and isinstance(rule['entity'], str):
                            entities_to_ground.add(rule['entity'].replace('_', ' '))
                        if 'targets' in rule and isinstance(rule['targets'], list):
                            for target in rule['targets']:
                                if isinstance(target, str):
                                    entities_to_ground.add(target.replace('_', ' '))
                analysis_json['entities_to_ground'] = list(entities_to_ground)
                return analysis_json

            except json.JSONDecodeError:
                print(f"--- ‚ö†Ô∏è L·ªói: Gemini kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá. S·ª≠ d·ª•ng fallback. Raw response: {raw_response_text}")
                return {"search_context": query, "spatial_rules": [], "fine_grained_verification": [], "entities_to_ground": []}

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi g·ªçi API Gemini: {e} ---")
            return {"search_context": query, "spatial_rules": [], "fine_grained_verification": [], "entities_to_ground": []}

    def perform_semantic_grounding(self, entities_to_ground: List[str]) -> Dict[str, str]:
        """
        D·ªãch c√°c nh√£n entity t·ª± do v·ªÅ c√°c nh√£n chu·∫©n c√≥ trong t·ª´ ƒëi·ªÉn.
        """
        if not entities_to_ground or self.known_entities_prompt_segment == "[]":
            return {}

        print(f"--- üß† B·∫Øt ƒë·∫ßu Semantic Grounding cho: {entities_to_ground} ---")
        
        prompt = (
            f"You are a helpful assistant. Your task is to map a list of input entities to the closest matching entities from a predefined dictionary.\n\n"
            f"**Predefined Dictionary:**\n{self.known_entities_prompt_segment}\n\n"
            f"**Input Entities to Map:**\n{json.dumps(entities_to_ground)}\n\n"
            f"Provide your answer ONLY as a valid JSON object mapping each input entity to its corresponding dictionary term. The keys of the JSON must be the original input entities."
        )
        
        try:
            response = self._gemini_api_call([prompt])
            raw_response_text = response.text.strip()
            if raw_response_text.startswith("```json"):
                raw_response_text = raw_response_text[7:-3].strip()
            
            grounding_map = json.loads(raw_response_text)
            print(f"    -> K·∫øt qu·∫£ Grounding Map: {grounding_map}")
            
            if not isinstance(grounding_map, dict):
                print(f"--- ‚ö†Ô∏è L·ªói Grounding: Gemini kh√¥ng tr·∫£ v·ªÅ dictionary. Fallback. ---")
                return {}
            return grounding_map

        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói trong qu√° tr√¨nh Semantic Grounding: {e} ---")
            return {}
            
    # --- C√ÅC H√ÄM C≈® KH√îNG THAY ƒê·ªîI ---
    def decompose_trake_query(self, query: str) -> List[str]:
        """Ph√¢n r√£ truy v·∫•n TRAKE b·∫±ng Gemini."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "T√¨m 4 kho·∫£nh kh·∫Øc ch√≠nh khi v·∫≠n ƒë·ªông vi√™n th·ª±c hi·ªán c√∫ nh·∫£y: (1) gi·∫≠m nh·∫£y, (2) bay qua x√†, (3) ti·∫øp ƒë·∫•t, (4) ƒë·ª©ng d·∫≠y."
        JSON: ["v·∫≠n ƒë·ªông vi√™n gi·∫≠m nh·∫£y", "v·∫≠n ƒë·ªông vi√™n bay qua x√†", "v·∫≠n ƒë·ªông vi√™n ti·∫øp ƒë·∫•t", "v·∫≠n ƒë·ªông vi√™n ƒë·ª©ng d·∫≠y"]

        Query: "{query}"
        JSON:
        """
        try:
            response = self._gemini_api_call([prompt])
            match = re.search(r"\[.*?\]", response.text, re.DOTALL)
            if match:
                return json.loads(match.group(0))
            return [query]
        except Exception:
            return [query]