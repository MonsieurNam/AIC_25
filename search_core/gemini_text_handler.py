import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from typing import Dict, Any, List, Set
import json
import re

from utils import api_retrier

SYSTEM_PROMPT = """
You are an expert multimedia scene analyst for a Vietnamese video search engine. Your task is to dissect a user's query into structured, machine-readable components. Do NOT answer the user's query. Your SOLE output must be a single, valid JSON object and nothing else, without any markdown formatting like ```json.

The user query will describe a visual scene. You must analyze it and extract three key components:

1.  **`search_context` (string):**
    *   An abstract, conceptual summary of the scene. IGNORE fine-grained details.
    *   FOCUS on the **essence, atmosphere, and overall action**.
    *   Example: For "a girl in a red dress holding a yellow balloon", the context is "a child enjoying an outdoor festival".

2.  **`spatial_rules` (list of objects):**
    *   Identify ALL spatial relationships (e.g., "between", "behind").
    *   Create a JSON object for each with `entity`, `relation` (`is_between`, `is_behind`, etc.), and `targets`.
    *   Use descriptive English labels (e.g., "person_white_shirt").
    *   If none, this MUST be an empty list `[]`.

3.  **`fine_grained_verification` (list of objects):**
    *   Identify specific objects whose appearance is described in great detail (colors, textures, specific parts). These are details the main search might miss.
    *   For each, create a JSON object with two fields:
        *   `target_entity` (string): The general class name of the object (e.g., "Bird", "Flower", "Dessert"). This MUST be a common, single-word noun.
        *   `detailed_description` (string): A full, descriptive English sentence detailing the object's specific visual characteristics as mentioned in the query.
    *   Example: For "a bird with bright red eyes", the object would be:
        `{"target_entity": "Bird", "detailed_description": "a bird with bright red eyes and blue-black feathers"}`
    *   If no such detailed descriptions exist, this MUST be an empty list `[]`.

**OUTPUT FORMAT EXAMPLE:**
User Query: "On a white plate, there is a panna cotta dessert decorated with red grape slices, a green mint leaf, and two small edible flowers (one red, one yellow)."

Your JSON output:
{
  "search_context": "a close-up shot of a gourmet dessert, panna cotta, being plated or displayed",
  "spatial_rules": [],
  "fine_grained_verification": [
    {
      "target_entity": "Grape",
      "detailed_description": "slices of red grapes used as a garnish"
    },
    {
      "target_entity": "Mint",
      "detailed_description": "a fresh green mint leaf on a dessert"
    },
    {
      "target_entity": "Flower",
      "detailed_description": "a small, edible red and yellow flower for decoration"
    }
  ]
}

Now, analyze the user's query and provide ONLY the JSON output.
"""

class GeminiTextHandler:
    """
    M·ªôt class chuy√™n d·ª•ng ƒë·ªÉ x·ª≠ l√Ω T·∫§T C·∫¢ c√°c t√°c v·ª• li√™n quan ƒë·∫øn vƒÉn b·∫£n
    b·∫±ng API c·ªßa Google Gemini (c·ª• th·ªÉ l√† model Flash).
    
    Bao g·ªìm: ph√¢n lo·∫°i t√°c v·ª•, ph√¢n t√≠ch chi ti·∫øt truy v·∫•n, v√† ph√¢n r√£ truy v·∫•n TRAKE.
    """

    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        """
        Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Text Handler.
        PHI√äN B·∫¢N ƒê√É S·ª¨A L·ªñI: L∆∞u tr·ªØ generation_config v√† safety_settings.
        """
        print(f"--- ‚ú® Kh·ªüi t·∫°o Gemini Text Handler v·ªõi model: {model_name} ---")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name)
            self.known_entities_prompt_segment: str = "" # S·∫Ω ƒë∆∞·ª£c n·∫°p sau
            
            # --- ‚úÖ L∆ØU TR·ªÆ C√ÅC C·∫§U H√åNH TH√ÄNH THU·ªòC T√çNH C·ª¶A CLASS ---
            self.generation_config = {
                "temperature": 0.1,
                "top_p": 0.95,
                "top_k": 64,
                "max_output_tokens": 8192,
                "response_mime_type": "application/json",
            }
            
            # C·∫•u h√¨nh an to√†n ƒë·ªÉ tr√°nh b·ªã block do c√°c n·ªôi dung nh·∫°y c·∫£m
            self.safety_settings = {
                'HATE': 'BLOCK_NONE',
                'HARASSMENT': 'BLOCK_NONE',
                'SEXUAL': 'BLOCK_NONE',
                'DANGEROUS': 'BLOCK_NONE'
            }
            
            # --- X√°c th·ª±c API Key b·∫±ng m·ªôt l·ªánh g·ªçi nh·ªè ---
            print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API Gemini... ---")
            # L·ªánh g·ªçi ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra xem API key c√≥ ho·∫°t ƒë·ªông kh√¥ng
            self.model.count_tokens("test") 
            print("--- ‚úÖ Tr·∫°ng th√°i API Gemini: OK ---")
            print("--- ‚úÖ Gemini Text Handler ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o v√† x√°c th·ª±c th√†nh c√¥ng! ---")

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o Gemini Handler: {e} ---")
            print("    -> Vui l√≤ng ki·ªÉm tra l·∫°i API Key v√† k·∫øt n·ªëi m·∫°ng.")
            # N√©m l·∫°i l·ªói ƒë·ªÉ qu√° tr√¨nh kh·ªüi t·∫°o backend c√≥ th·ªÉ d·ª´ng l·∫°i n·∫øu c·∫ßn
            raise e

    @api_retrier(max_retries=3, initial_delay=1)
    def _gemini_text_call(self, prompt: str):
        """H√†m con ƒë∆∞·ª£c "trang tr√≠", ch·ªâ ƒë·ªÉ th·ª±c hi·ªán l·ªánh g·ªçi API text c·ªßa Gemini."""
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        response = self.model.generate_content(prompt, safety_settings=safety_settings, generation_config=generation_config)
        return response

    def health_check(self):
        """Th·ª±c hi·ªán m·ªôt l·ªánh g·ªçi API ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra key v√† k·∫øt n·ªëi."""
        print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API Gemini... ---")
        try:
            self.model.count_tokens("ki·ªÉm tra")
            print("--- ‚úÖ Tr·∫°ng th√°i API Gemini: OK ---")
            return True
        except Exception as e:
            print(f"--- ‚ùå L·ªói API Gemini: {e} ---")
            raise e

    def analyze_task_type(self, query: str) -> str:
        """Ph√¢n lo·∫°i truy v·∫•n b·∫±ng Gemini, s·ª≠ d·ª•ng prompt c√≥ Quy t·∫Øc ∆Øu ti√™n."""
        prompt = f"""
        You are a highly precise query classifier. Your task is to classify a Vietnamese query into one of four categories: TRAKE, QNA, or KIS. You MUST follow a strict priority order.

        **Priority Order for Classification (Check from top to bottom):**
        
        1.  **First, check for TRAKE:** Does the query ask for a SEQUENCE of DIFFERENT, ordered actions? Look for patterns like "(1)...(2)...", "b∆∞·ªõc 1... b∆∞·ªõc 2", "sau ƒë√≥". If it matches, classify as **TRAKE** and stop.
            - Example: "ng∆∞·ªùi ƒë√†n √¥ng ƒë·ª©ng l√™n r·ªìi b∆∞·ªõc ƒëi"

        2.  **Then, check for QNA:** If not TRAKE, does the query ask a **direct question** that expects a factual answer about something in the scene? This is more than just describing a scene. Look for:
            - **Interrogative words:** "ai", "c√°i g√¨", "·ªü ƒë√¢u", "khi n√†o", "t·∫°i sao", "nh∆∞ th·∫ø n√†o", "m√†u g√¨", "h√£ng n√†o", etc.
            - **Question structures:** "c√≥ ph·∫£i l√†...", "ƒëang l√†m g√¨", "l√† ai", "tr√¥ng nh∆∞ th·∫ø n√†o".
            - A question mark "?".
            If it matches, classify as **QNA** and stop.
            - Example: "ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c √°o m√†u g√¨?" -> QNA
            - Example: "ai l√† ng∆∞·ªùi ƒë√†n √¥ng ƒëang ph√°t bi·ªÉu?" -> QNA
            - Example: "c√≥ bao nhi√™u chi·∫øc xe tr√™n ƒë∆∞·ªùng?" -> This asks for a count of a single scene, so it is **QNA**. 

        3.  **Default to KIS:** If the query is a statement or a descriptive phrase looking for a moment, classify as **KIS**. It describes "what to find", not "what to answer".
            - Example: "c·∫£nh ng∆∞·ªùi ƒë√†n √¥ng ƒëang ph√°t bi·ªÉu" -> KIS
            - Example: "t√¨m ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c √°o ƒë·ªè" -> KIS
            - Example: "m·ªôt chi·∫øc xe ƒëang ch·∫°y" -> KIS

        **Your Task:**
        Follow the priority order strictly. Analyze the query below and return ONLY the final category as a single word.

        **Query:** "{query}"
        **Category:**
        """
        try:
            response = self._gemini_text_call(prompt)
            task_type = response.text.strip().upper()
            if task_type in ["KIS", "QNA", "TRAKE"]:
                return task_type
            return "KIS"
        except Exception:
            return "KIS" # Fallback an to√†n
        
    def analyze_query_fully(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch s√¢u m·ªôt truy v·∫•n, tr√≠ch xu·∫•t ng·ªØ c·∫£nh, ƒë·ªëi t∆∞·ª£ng, v√† c√°c quy t·∫Øc.
        PHI√äN B·∫¢N N√ÇNG C·∫§P: X·ª≠ l√Ω output JSON c√≥ c·∫•u tr√∫c.
        """
        print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n c√≥ c·∫•u tr√∫c b·∫±ng Gemini... ---")
        
        user_prompt = f"Entities Dictionary for Grounding: {self.known_entities_prompt_segment}\n\nUser Query: \"{query}\""
        
        try:
            response = self.model.generate_content(
                [SYSTEM_PROMPT, user_prompt],
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            raw_response_text = response.text.strip()
            
            try:
                if raw_response_text.startswith("```json"):
                    raw_response_text = raw_response_text[7:]
                if raw_response_text.endswith("```"):
                    raw_response_text = raw_response_text[:-3]

                analysis_json = json.loads(raw_response_text)
                
                entities_to_ground = set()
                if 'spatial_rules' in analysis_json and isinstance(analysis_json['spatial_rules'], list):
                    for rule in analysis_json['spatial_rules']:
                        if 'entity' in rule and isinstance(rule['entity'], str):
                            entities_to_ground.add(rule['entity'].replace('_', ' '))
                        if 'targets' in rule and isinstance(rule['targets'], list):
                            for target in rule['targets']:
                                if isinstance(target, str):
                                    entities_to_ground.add(target.replace('_', ' '))
                analysis_json['entities_to_ground'] = list(entities_to_ground)

                return analysis_json

            except json.JSONDecodeError:
                print(f"--- ‚ö†Ô∏è L·ªói: Gemini kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá. S·ª≠ d·ª•ng fallback. ---")
                print(f"    Raw response: {raw_response_text}")
                return {
                    "search_context": query, # D√πng query g·ªëc l√†m context
                    "spatial_rules": [],
                    "fine_grained_verification": [],
                    "grounded_entities": []
                }

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi g·ªçi API Gemini: {e} ---")
            import traceback
            traceback.print_exc()
            # Fallback trong tr∆∞·ªùng h·ª£p API l·ªói
            return {
                "search_context": query,
                "spatial_rules": [],
                "fine_grained_verification": [],
                "grounded_entities": []
            }

    def enhance_query(self, query: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch v√† tr√≠ch xu·∫•t th√¥ng tin truy v·∫•n b·∫±ng Gemini."""
        fallback_result = {
            'search_context': query, 'specific_question': "", 'aggregation_instruction': "",
            'objects_vi': [], 'objects_en': []
        }
        prompt = f"""
        Analyze a Vietnamese user query for a video search system. **Return ONLY a valid JSON object** with five keys: "search_context", "specific_question", "aggregation_instruction", "objects_vi", and "objects_en".

        **Rules:**
        1.  `search_context`: A Vietnamese phrase for finding the general scene. This is used for vector search.
        2.  `specific_question`: The specific question to ask the Vision model for EACH individual frame.
        3.  `aggregation_instruction`: The final instruction for the AI to synthesize all individual answers. This should reflect the user's ultimate goal (e.g., counting, listing, summarizing).
        4.  `objects_vi`: A list of Vietnamese nouns/entities.
        5.  `objects_en`: The English translation for EACH item in `objects_vi`.

        **Example (VQA):**
        Query: "Trong video quay c·∫£nh b·ªØa ti·ªác, ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè ƒëang c·∫ßm ly m√†u g√¨?"
        JSON: {{"search_context": "c·∫£nh b·ªØa ti·ªác c√≥ ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè", "specific_question": "c√¥ ·∫•y ƒëang c·∫ßm ly m√†u g√¨?", "aggregation_instruction": "tr·∫£ l·ªùi c√¢u h·ªèi ng∆∞·ªùi ph·ª• n·ªØ c·∫ßm ly m√†u g√¨", "objects_vi": ["b·ªØa ti·ªác", "ng∆∞·ªùi ph·ª• n·ªØ", "v√°y ƒë·ªè"], "objects_en": ["party", "woman", "red dress"]}}

        **Example (Track-VQA):**
        Query: "ƒë·∫øm xem c√≥ bao nhi√™u con l√¢n trong bu·ªïi bi·ªÉu di·ªÖn"
        JSON: {{"search_context": "bu·ªïi bi·ªÉu di·ªÖn m√∫a l√¢n", "specific_question": "c√≥ con l√¢n n√†o trong ·∫£nh n√†y kh√¥ng v√† m√†u g√¨?", "aggregation_instruction": "t·ª´ c√°c quan s√°t, ƒë·∫øm t·ªïng s·ªë l√¢n v√† li·ªát k√™ m√†u s·∫Øc c·ªßa ch√∫ng", "objects_vi": ["con l√¢n", "bu·ªïi bi·ªÉu di·ªÖn"], "objects_en": ["lion dance", "performance"]}}

        **Your Task:**
        Analyze the query below and generate the JSON.

        **Query:** "{query}"
        **JSON:**
        """
        try:
            response = self._gemini_text_call(prompt)
            # Tr√≠ch xu·∫•t JSON t·ª´ markdown block (Gemini th∆∞·ªùng tr·∫£ v·ªÅ nh∆∞ v·∫≠y)
            match = re.search(r"```json\s*(\{.*?\})\s*```", response.text, re.DOTALL)
            if not match:
                match = re.search(r"(\{.*?\})", response.text, re.DOTALL) # Th·ª≠ t√¨m JSON kh√¥ng c√≥ markdown
            
            if match:
                result = json.loads(match.group(1))
                # Validate ...
                return result
            return fallback_result
        except Exception as e:
            print(f"L·ªói Gemini enhance_query: {e}")
            return fallback_result
            
    def decompose_trake_query(self, query: str) -> List[str]:
        """Ph√¢n r√£ truy v·∫•n TRAKE b·∫±ng Gemini."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "T√¨m 4 kho·∫£nh kh·∫Øc ch√≠nh khi v·∫≠n ƒë·ªông vi√™n th·ª±c hi·ªán c√∫ nh·∫£y: (1) gi·∫≠m nh·∫£y, (2) bay qua x√†, (3) ti·∫øp ƒë·∫•t, (4) ƒë·ª©ng d·∫≠y."
        JSON: ["v·∫≠n ƒë·ªông vi√™n gi·∫≠m nh·∫£y", "v·∫≠n ƒë·ªông vi√™n bay qua x√†", "v·∫≠n ƒë·ªông vi√™n ti·∫øp ƒë·∫•t", "v·∫≠n ƒë·ªông vi√™n ƒë·ª©ng d·∫≠y"]

        Query: "{query}"
        JSON:
        """
        try:
            response = self._gemini_text_call(prompt)
            match = re.search(r"\[.*?\]", response.text, re.DOTALL)
            if match:
                return json.loads(match.group(0))
            return [query]
        except Exception:
            return [query]
        
    def load_known_entities(self, known_entities: Set[str]):
        """
        Chu·∫©n b·ªã v√† cache l·∫°i ph·∫ßn prompt ch·ª©a t·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng.
        Ch·ªâ c·∫ßn g·ªçi m·ªôt l·∫ßn khi MasterSearcher kh·ªüi t·∫°o.
        """
        if not known_entities:
            print("--- ‚ö†Ô∏è T·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng r·ªóng. Semantic Grounding s·∫Ω kh√¥ng ho·∫°t ƒë·ªông. ---")
            return
        
        # S·∫Øp x·∫øp ƒë·ªÉ ƒë·∫£m b·∫£o prompt nh·∫•t qu√°n gi·ªØa c√°c l·∫ßn ch·∫°y
        sorted_entities = sorted(list(known_entities))
        # ƒê·ªãnh d·∫°ng th√†nh chu·ªói JSON ƒë·ªÉ nh√∫ng v√†o prompt
        self.known_entities_prompt_segment = json.dumps(sorted_entities)
        print(f"--- ‚úÖ GeminiTextHandler: ƒê√£ n·∫°p {len(sorted_entities)} th·ª±c th·ªÉ v√†o b·ªô nh·ªõ prompt. ---")

    def perform_semantic_grounding(self, entities_to_ground: List[str]) -> Dict[str, str]:
        """
        D·ªãch c√°c nh√£n entity t·ª± do v·ªÅ c√°c nh√£n chu·∫©n c√≥ trong t·ª´ ƒëi·ªÉn.
        PHI√äN B·∫¢N N√ÇNG C·∫§P: Tr·∫£ v·ªÅ m·ªôt dictionary mapping: {entity_g·ªëc: entity_ƒë√£_d·ªãch}.
        """
        if not entities_to_ground or not self.known_entities_prompt_segment:
            return {}

        print(f"--- üß† B·∫Øt ƒë·∫ßu Semantic Grounding cho: {entities_to_ground} ---")
        
        # Prompt ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ y√™u c·∫ßu Gemini tr·∫£ v·ªÅ JSON object
        prompt = (
            f"You are a helpful assistant. Your task is to map a list of input entities to the closest matching entities from a predefined dictionary. "
            f"For each input entity, find the single most appropriate term from the dictionary.\n\n"
            f"**Predefined Dictionary:**\n{self.known_entities_prompt_segment}\n\n"
            f"**Input Entities to Map:**\n{json.dumps(entities_to_ground)}\n\n"
            f"Provide your answer ONLY as a valid JSON object mapping each input entity to its corresponding dictionary term. "
            f"The keys of the JSON must be the original input entities. "
            f"Example format: {{\"input entity 1\": \"dictionary term 1\", \"input entity 2\": \"dictionary term 2\"}}"
        )
        
        try:
            # S·ª≠ d·ª•ng generation_config ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong __init__
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            # X·ª≠ l√Ω response text ƒë·ªÉ ƒë·∫£m b·∫£o n√≥ l√† JSON h·ª£p l·ªá
            raw_response_text = response.text.strip()
            if raw_response_text.startswith("```json"):
                raw_response_text = raw_response_text[7:]
            if raw_response_text.endswith("```"):
                raw_response_text = raw_response_text[:-3]

            # Parse chu·ªói JSON th√†nh dictionary
            grounding_map = json.loads(raw_response_text)
            print(f"    -> K·∫øt qu·∫£ Grounding Map: {grounding_map}")
            
            # Ki·ªÉm tra xem output c√≥ ph·∫£i l√† dictionary kh√¥ng
            if not isinstance(grounding_map, dict):
                print(f"--- ‚ö†Ô∏è L·ªói Grounding: Gemini kh√¥ng tr·∫£ v·ªÅ dictionary. Fallback. ---")
                return {}

            return grounding_map

        except (json.JSONDecodeError, Exception) as e:
            print(f"--- ‚ö†Ô∏è L·ªói trong qu√° tr√¨nh Semantic Grounding: {e} ---")
            # Fallback: Tr·∫£ v·ªÅ mapping r·ªóng n·∫øu c√≥ l·ªói
            return {}