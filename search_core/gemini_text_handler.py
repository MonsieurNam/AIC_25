# ==============================================================================
# GEMINI TEXT HANDLER - PHI√äN B·∫¢N CU·ªêI C√ôNG (ENTITY-AWARE)
# File: gemini_text_handler.py
#
# THAY ƒê·ªîI C·ªêT L√ïI:
#   - S·ª≠a ƒë·ªïi SYSTEM_PROMPT ƒë·ªÉ t√≠ch h·ª£p "T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng To√†n c·ª•c",
#     h∆∞·ªõng d·∫´n Gemini ∆∞u ti√™n s·ª≠ d·ª•ng c√°c nh√£n th·ª±c th·ªÉ ƒë√£ bi·∫øt.
#   - T·ªëi ∆∞u h√≥a vi·ªác t·∫°o prompt ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa Semantic Grounding
#     v√† ph√¢n t√≠ch kh√¥ng gian.
# ==============================================================================

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from typing import Dict, Any, List, Set
import json
import re

from utils import api_retrier

class GeminiTextHandler:
    """
    M·ªôt class chuy√™n d·ª•ng ƒë·ªÉ x·ª≠ l√Ω T·∫§T C·∫¢ c√°c t√°c v·ª• li√™n quan ƒë·∫øn vƒÉn b·∫£n
    b·∫±ng API c·ªßa Google Gemini. PHI√äN B·∫¢N N√ÇNG C·∫§P (ENTITY-AWARE).
    """

    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        """
        Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Text Handler.
        """
        print(f"--- ‚ú® Kh·ªüi t·∫°o Gemini Text Handler v·ªõi model: {model_name} ---")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name)
            self.known_entities_prompt_segment: str = "[]" # M·∫∑c ƒë·ªãnh l√† list r·ªóng d·∫°ng chu·ªói
            
            # --- C·∫•u h√¨nh API call ---
            self.generation_config = {
                "temperature": 0.1,
                "top_p": 0.95,
                "top_k": 64,
                "max_output_tokens": 8192,
                "response_mime_type": "application/json",
            }
            self.safety_settings = {
                'HATE': 'BLOCK_NONE', 'HARASSMENT': 'BLOCK_NONE',
                'SEXUAL': 'BLOCK_NONE', 'DANGEROUS': 'BLOCK_NONE'
            }
            
            # --- X√°c th·ª±c API Key b·∫±ng m·ªôt l·ªánh g·ªçi nh·ªè ---
            print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API Gemini... ---")
            self.model.count_tokens("test") 
            print("--- ‚úÖ Tr·∫°ng th√°i API Gemini: OK ---")

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o Gemini Handler: {e} ---")
            print("    -> Vui l√≤ng ki·ªÉm tra l·∫°i API Key v√† k·∫øt n·ªëi m·∫°ng.")
            raise e

    def _get_system_prompt(self) -> str:
        """
        H√†m t·∫°o ra SYSTEM_PROMPT ƒë·ªông, nh√∫ng danh s√°ch 600 th·ª±c th·ªÉ c·ªßa OpenImagesV4.
        ƒê√¢y l√† phi√™n b·∫£n "chuy√™n gia", ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho d·ªØ li·ªáu c·ªßa cu·ªôc thi.
        """
        return f"""
    You are a highly precise multimedia scene analyst. Your task is to deconstruct a user's query into a structured JSON object. Your analysis is for a video search engine whose object detection system is based on the **OpenImagesV4 dataset**.

    **CRITICAL INSTRUCTION: The detection system ONLY knows the following 600 object classes. When creating `entity` and `targets` for `spatial_rules`, you MUST use the EXACT labels from this list. This is the most important rule.**

    **List of 600 Known Object Classes (OpenImagesV4 Vocabulary):**
    {self.known_entities_prompt_segment}

    **Analysis Rules:**
    1.  **If the user describes an object that is in the list**, use the label from the list.
        *   Example: User says "bi·ªÉu t∆∞·ª£ng con cua kh·ªïng l·ªì". The closest known entity is "Sculpture" or "Building". You MUST choose one of them. DO NOT create a new label like "giant_crab_symbol".
    2.  **If the user describes an object that is NOT in the list**, find the most logical **parent class or component** from the list.
        *   Example: User says "b·∫£n ƒë·ªì Vi·ªát Nam l√†m b·∫±ng tr√°i c√¢y". The known list has "Fruit", "Apple", "Orange", but not "map". You should use "Fruit" as the best available approximation.
    3.  **Your JSON output MUST contain three components:**
        *   `search_context`: A general summary of the scene.
        *   `spatial_rules`: A list of spatial relationships using ONLY the labels from the provided list.
        *   `fine_grained_verification`: A list for detailed visual attributes not covered by the object labels.

    ---
    **EXAMPLE:**
    User Query: "Nhi·ªÅu ng∆∞·ªùi m·∫∑c √°o c·ªù ƒë·ªè sao v√†ng ƒë·ª©ng tr∆∞·ªõc bi·ªÉu t∆∞·ª£ng m·ªôt con cua kh·ªïng l·ªì."

    **Your CORRECT JSON output (because 'Sculpture' and 'Person' are in the list):**
    {{
    "search_context": "a crowd of people celebrating in front of a large sculpture",
    "spatial_rules": [
        {{
        "entity": "Sculpture",
        "relation": "is_behind",
        "targets": ["Person"]
        }}
    ],
    "fine_grained_verification": [
        {{
        "target_entity": "Flag",
        "detailed_description": "a Vietnamese flag (red flag with a yellow star)"
        }},
        {{
        "target_entity": "Sculpture",
        "detailed_description": "a giant sculpture shaped like a crab"
        }}
    ]
    }}
    ---
    Now, analyze the user's query and provide ONLY the JSON output, strictly following these rules.
    """

    @api_retrier(max_retries=3, initial_delay=1)
    def _gemini_api_call(self, content_list: list) -> genai.GenerativeModel.generate_content:
        """H√†m con ƒë∆∞·ª£c 'trang tr√≠', chuy√™n th·ª±c hi·ªán l·ªánh g·ªçi API c·ªßa Gemini."""
        return self.model.generate_content(
            content_list,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings
        )

    def load_known_entities(self, known_entities: Set[str]):
        """
        Chu·∫©n b·ªã v√† cache l·∫°i ph·∫ßn prompt ch·ª©a t·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng.
        Ch·ªâ c·∫ßn g·ªçi m·ªôt l·∫ßn khi MasterSearcher kh·ªüi t·∫°o.
        """
        if not known_entities:
            print("--- ‚ö†Ô∏è T·ª´ ƒëi·ªÉn ƒë·ªëi t∆∞·ª£ng r·ªóng. Semantic Grounding s·∫Ω kh√¥ng ho·∫°t ƒë·ªông t·ªëi ∆∞u. ---")
            return
        
        sorted_entities = sorted(list(known_entities))
        # ƒê·ªãnh d·∫°ng th√†nh chu·ªói JSON ƒë·ªÉ nh√∫ng v√†o prompt
        self.known_entities_prompt_segment = json.dumps(sorted_entities)
        print(f"--- ‚úÖ GeminiTextHandler: ƒê√£ n·∫°p {len(sorted_entities)} th·ª±c th·ªÉ v√†o b·ªô nh·ªõ prompt. ---")

    def analyze_query_fully(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch s√¢u m·ªôt truy v·∫•n, tr√≠ch xu·∫•t ng·ªØ c·∫£nh, ƒë·ªëi t∆∞·ª£ng, v√† c√°c quy t·∫Øc.
        """
        print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n c√≥ c·∫•u tr√∫c b·∫±ng Gemini (Entity-Aware)... ---")
        
        system_prompt = self._get_system_prompt()
        user_prompt = f"User Query: \"{query}\""
        
        try:
            response = self._gemini_api_call([system_prompt, user_prompt])
            raw_response_text = response.text.strip()
            
            try:
                if raw_response_text.startswith("```json"):
                    raw_response_text = raw_response_text[7:-3].strip()
                analysis_json = json.loads(raw_response_text)
                
                # Tr√≠ch xu·∫•t c√°c th·ª±c th·ªÉ c·∫ßn ƒë∆∞·ª£c "grounding" sau n√†y
                entities_to_ground = set()
                if 'spatial_rules' in analysis_json and isinstance(analysis_json['spatial_rules'], list):
                    for rule in analysis_json['spatial_rules']:
                        if 'entity' in rule and isinstance(rule['entity'], str):
                            entities_to_ground.add(rule['entity'].replace('_', ' '))
                        if 'targets' in rule and isinstance(rule['targets'], list):
                            for target in rule['targets']:
                                if isinstance(target, str):
                                    entities_to_ground.add(target.replace('_', ' '))
                analysis_json['entities_to_ground'] = list(entities_to_ground)
                return analysis_json

            except json.JSONDecodeError:
                print(f"--- ‚ö†Ô∏è L·ªói: Gemini kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá. S·ª≠ d·ª•ng fallback. Raw response: {raw_response_text}")
                return {"search_context": query, "spatial_rules": [], "fine_grained_verification": [], "entities_to_ground": []}

        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi g·ªçi API Gemini: {e} ---")
            return {"search_context": query, "spatial_rules": [], "fine_grained_verification": [], "entities_to_ground": []}

    def perform_semantic_grounding(self, entities_to_ground: List[str]) -> Dict[str, str]:
        """
        D·ªãch c√°c nh√£n entity t·ª± do v·ªÅ c√°c nh√£n chu·∫©n c√≥ trong t·ª´ ƒëi·ªÉn.
        """
        if not entities_to_ground or self.known_entities_prompt_segment == "[]":
            return {}

        print(f"--- üß† B·∫Øt ƒë·∫ßu Semantic Grounding cho: {entities_to_ground} ---")
        
        prompt = (
            f"You are a helpful assistant. Your task is to map a list of input entities to the closest matching entities from a predefined dictionary.\n\n"
            f"**Predefined Dictionary:**\n{self.known_entities_prompt_segment}\n\n"
            f"**Input Entities to Map:**\n{json.dumps(entities_to_ground)}\n\n"
            f"Provide your answer ONLY as a valid JSON object mapping each input entity to its corresponding dictionary term. The keys of the JSON must be the original input entities."
        )
        
        try:
            response = self._gemini_api_call([prompt])
            raw_response_text = response.text.strip()
            if raw_response_text.startswith("```json"):
                raw_response_text = raw_response_text[7:-3].strip()
            
            grounding_map = json.loads(raw_response_text)
            print(f"    -> K·∫øt qu·∫£ Grounding Map: {grounding_map}")
            
            if not isinstance(grounding_map, dict):
                print(f"--- ‚ö†Ô∏è L·ªói Grounding: Gemini kh√¥ng tr·∫£ v·ªÅ dictionary. Fallback. ---")
                return {}
            return grounding_map

        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói trong qu√° tr√¨nh Semantic Grounding: {e} ---")
            return {}
            
    # --- C√ÅC H√ÄM C≈® KH√îNG THAY ƒê·ªîI ---
    def decompose_trake_query(self, query: str) -> List[str]:
        """Ph√¢n r√£ truy v·∫•n TRAKE b·∫±ng Gemini."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "T√¨m 4 kho·∫£nh kh·∫Øc ch√≠nh khi v·∫≠n ƒë·ªông vi√™n th·ª±c hi·ªán c√∫ nh·∫£y: (1) gi·∫≠m nh·∫£y, (2) bay qua x√†, (3) ti·∫øp ƒë·∫•t, (4) ƒë·ª©ng d·∫≠y."
        JSON: ["v·∫≠n ƒë·ªông vi√™n gi·∫≠m nh·∫£y", "v·∫≠n ƒë·ªông vi√™n bay qua x√†", "v·∫≠n ƒë·ªông vi√™n ti·∫øp ƒë·∫•t", "v·∫≠n ƒë·ªông vi√™n ƒë·ª©ng d·∫≠y"]

        Query: "{query}"
        JSON:
        """
        try:
            response = self._gemini_api_call([prompt])
            match = re.search(r"\[.*?\]", response.text, re.DOTALL)
            if match:
                return json.loads(match.group(0))
            return [query]
        except Exception:
            return [query]
    def get_text_response(self, prompt: str, system_prompt: str) -> str:
        """
        G·ª≠i m·ªôt prompt t·ªõi Gemini v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d·∫°ng text.
        ƒê√¢y l√† giao di·ªán chung, s·∫°ch s·∫Ω cho c√°c module kh√°c s·ª≠ d·ª•ng.
        """
        try:
            # G·ª≠i c·∫£ system prompt v√† user prompt
            response = self._gemini_api_call([system_prompt, prompt])
            return response.text.strip()
        except Exception as e:
            print(f"--- ‚ùå L·ªói nghi√™m tr·ªçng khi g·ªçi API Gemini qua get_text_response: {e} ---")
            # Tr·∫£ v·ªÅ chu·ªói r·ªóng ƒë·ªÉ b√™n g·ªçi c√≥ th·ªÉ x·ª≠ l√Ω fallback m·ªôt c√°ch an to√†n
            return ""