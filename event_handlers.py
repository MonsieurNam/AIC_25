import gradio as gr
import pandas as pd
import numpy as np
import time
import os
import traceback
import json
import re
from io import StringIO
from typing import Dict, List
import glob

# --- Local imports ---
from config import ITEMS_PER_PAGE, MAX_SUBMISSION_RESULTS, VIDEO_BASE_PATH, TRANSCRIPTS_JSON_DIR
from ui_helpers import create_detailed_info_html
from search_core.task_analyzer import TaskType
from utils.formatting import (
    format_list_for_submission, 
    format_results_for_mute_gallery,
    format_submission_list_to_csv_string
)
from utils import create_video_segment

# ==============================================================================
# === B·ªò NH·ªö CACHE C·ª§C B·ªò "T·ª∞ L·ª∞C C√ÅNH SINH" ===
# ==============================================================================
print("--- [event_handlers.py] ƒêang x√¢y d·ª±ng B·ªô nh·ªõ ƒë·ªám cho ƒê∆∞·ªùng d·∫´n Video... ---")
try:
    _all_video_files = glob.glob(os.path.join(VIDEO_BASE_PATH, "**", "*.mp4"), recursive=True)
    VIDEO_PATH_MAP_CACHE = {os.path.basename(f).replace('.mp4', ''): f for f in _all_video_files}
    print(f"--- [event_handlers.py] ƒê√£ cache {len(VIDEO_PATH_MAP_CACHE)} ƒë∆∞·ªùng d·∫´n video. ---")
except Exception as e:
    print(f"--- [event_handlers.py] L·ªñI khi x√¢y d·ª±ng cache ƒë∆∞·ªùng d·∫´n video: {e} ---")
    VIDEO_PATH_MAP_CACHE = {}

# ==============================================================================
# === C√ÅC H√ÄM X·ª¨ L√ù S·ª∞ KI·ªÜN ===
# ==============================================================================

def clear_analysis_panel():
    """Tr·∫£ v·ªÅ c√°c gi√° tr·ªã r·ªóng ƒë·ªÉ d·ªçn d·∫πp Tr·∫°m Ph√¢n t√≠ch H·ª£p nh·∫•t."""
    return None, None, "", ""

def perform_search(query_text: str, num_results: int, w_clip: float, w_obj: float, w_semantic: float, lambda_mmr: float, master_searcher):
    if not query_text.strip():
        gr.Warning("Vui l√≤ng nh·∫≠p truy v·∫•n t√¨m ki·∫øm!")
        return [], "<div style='color: orange;'>‚ö†Ô∏è Vui l√≤ng nh·∫≠p truy v·∫•n.</div>", None, "Trang 1 / 1", [], 1
    gr.Info("B·∫Øt ƒë·∫ßu qu√©t visual...")
    try:
        config = {"top_k_final": int(num_results), "w_clip": w_clip, "w_obj": w_obj, "w_semantic": w_semantic, "lambda_mmr": lambda_mmr}
        start_time = time.time()
        full_response = master_searcher.search(query=query_text, config=config)
        search_time = time.time() - start_time
    except Exception as e:
        traceback.print_exc()
        return [], f"<div style='color: red;'>üî• L·ªói backend: {e}</div>", None, "Trang 1 / 1", [], 1
    gallery_paths = format_results_for_mute_gallery(full_response)
    num_found = len(gallery_paths)
    task_type_msg = full_response.get('task_type', TaskType.KIS).value
    status_msg = f"<div style='color: {'#166534' if num_found > 0 else '#d97706'};'>{'‚úÖ' if num_found > 0 else 'üòî'} **{task_type_msg}** | T√¨m th·∫•y {num_found} k·∫øt qu·∫£ ({search_time:.2f}s).</div>"
    initial_gallery_view = gallery_paths[:ITEMS_PER_PAGE]
    total_pages = int(np.ceil(num_found / ITEMS_PER_PAGE)) or 1
    page_info = f"Trang 1 / {total_pages}"
    return initial_gallery_view, status_msg, full_response, page_info, gallery_paths, 1

def update_gallery_page(gallery_items: list, current_page: int, direction: str):
    if not gallery_items: return [], 1, "Trang 1 / 1"
    total_items = len(gallery_items)
    total_pages = int(np.ceil(total_items / ITEMS_PER_PAGE)) or 1
    new_page = min(total_pages, current_page + 1) if direction == "‚ñ∂Ô∏è Trang sau" else max(1, current_page - 1)
    start_index = (new_page - 1) * ITEMS_PER_PAGE
    end_index = start_index + ITEMS_PER_PAGE
    return gallery_items[start_index:end_index], new_page, f"Trang {new_page} / {total_pages}"

def handle_transcript_search(query1: str, query2: str, query3: str, transcript_searcher):
    gr.Info("B·∫Øt ƒë·∫ßu ƒëi·ªÅu tra transcript...")
    results = None
    if query1.strip(): results = transcript_searcher.search(query1, current_results=results)
    if query2.strip(): results = transcript_searcher.search(query2, current_results=results)
    if query3.strip(): results = transcript_searcher.search(query3, current_results=results)
    if results is None:
        return "Nh·∫≠p truy v·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒëi·ªÅu tra.", pd.DataFrame(), None
    count_str = f"T√¨m th·∫•y: {len(results)} k·∫øt qu·∫£."
    display_df = results[['video_id', 'timestamp', 'transcript_text', 'keyframe_path']]
    return count_str, display_df, results

def clear_transcript_search():
    analysis_clear_vals = clear_analysis_panel()
    return ("", "", "", "T√¨m th·∫•y: 0 k·∫øt qu·∫£.", pd.DataFrame(), None, *analysis_clear_vals)

def on_gallery_select(response_state: dict, current_page: int, evt: gr.SelectData):
    empty_return = (None, None, "", "", None, "", "0.0", None)
    if not isinstance(evt, gr.SelectData) or not response_state: return empty_return
    results = response_state.get("results", [])
    global_index = (current_page - 1) * ITEMS_PER_PAGE + evt.index
    if not results or global_index >= len(results): return empty_return
    selected_result = results[global_index]
    video_path, timestamp, keyframe_path, video_id = selected_result.get('video_path'), selected_result.get('timestamp', 0.0), selected_result.get('keyframe_path'), selected_result.get('video_id')
    video_clip_path = create_video_segment(video_path, timestamp, duration=30)
    analysis_html = create_detailed_info_html(selected_result, response_state.get("task_type"))
    return video_clip_path, keyframe_path, "Transcript ch·ªâ hi·ªÉn th·ªã khi ch·ªçn t·ª´ Tab 'Tai Th√≠nh'.", analysis_html, selected_result, video_id, str(timestamp), video_path

def on_transcript_select(results_state: pd.DataFrame, evt: gr.SelectData):
    empty_return = (None, None, "Click v√†o m·ªôt d√≤ng k·∫øt qu·∫£...", "", None, "", "0.0", None, None)
    if not isinstance(evt, gr.SelectData) or results_state is None or results_state.empty: return empty_return
    try:
        selected_index = evt.index[0]
        selected_row = results_state.iloc[selected_index]
        video_id, timestamp, keyframe_path = selected_row['video_id'], selected_row['timestamp'], selected_row['keyframe_path']
        video_path = VIDEO_PATH_MAP_CACHE.get(video_id)
        video_clip_path = create_video_segment(video_path, timestamp, duration=30) if video_path and os.path.exists(video_path) else None
        transcript_json_path = os.path.join(TRANSCRIPTS_JSON_DIR, f"{video_id}.json")
        full_transcript_text = f"Th√¥ng b√°o: Kh√¥ng c√≥ file transcript cho video '{video_id}'."
        if os.path.exists(transcript_json_path):
            with open(transcript_json_path, 'r', encoding='utf-8') as f: full_transcript_text = json.load(f).get("text", "").strip()
        candidate = {"video_id": video_id, "timestamp": timestamp, "keyframe_id": f"transcript_{timestamp:.2f}s"}
        return video_clip_path, keyframe_path, full_transcript_text, "", candidate, video_id, str(timestamp), video_path, selected_index
    except Exception as e:
        gr.Error(f"L·ªói khi x·ª≠ l√Ω l·ª±a ch·ªçn transcript: {e}")
        traceback.print_exc()
        return empty_return

def get_full_video_path_for_button(video_path):
    if video_path and os.path.exists(video_path): return video_path
    gr.Warning("Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n video g·ªëc ƒë·ªÉ m·ªü.")
    return None

def add_to_submission_list(submission_list: list, candidate: dict, response_state: dict, position: str):
    if not candidate:
        gr.Warning("Ch∆∞a c√≥ ·ª©ng vi√™n n√†o ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ th√™m!")
        return submission_list, format_submission_list_to_csv_string(submission_list)
    task_type = response_state.get("task_type", TaskType.KIS)
    item_to_add = {**candidate, 'task_type': task_type}
    if len(submission_list) < MAX_SUBMISSION_RESULTS:
        if position == 'top': submission_list.insert(0, item_to_add)
        else: submission_list.append(item_to_add)
        gr.Success(f"ƒê√£ th√™m k·∫øt qu·∫£ v√†o {'ƒë·∫ßu' if position == 'top' else 'cu·ªëi'} danh s√°ch!")
    else:
        gr.Warning(f"Danh s√°ch ƒë√£ ƒë·∫°t gi·ªõi h·∫°n {MAX_SUBMISSION_RESULTS} k·∫øt qu·∫£.")
    return submission_list, format_submission_list_to_csv_string(submission_list)

def add_transcript_result_to_submission(submission_list: list, results_state: pd.DataFrame, evt: gr.SelectData, position: str):
    if not isinstance(evt, gr.SelectData) or results_state is None or results_state.empty:
        gr.Warning("Vui l√≤ng ch·ªçn m·ªôt k·∫øt qu·∫£ t·ª´ b·∫£ng transcript tr∆∞·ªõc khi th√™m!")
        return submission_list, format_submission_list_to_csv_string(submission_list)
    try:
        selected_index = evt.index[0]
        selected_row = results_state.iloc[selected_index]
        candidate = {"video_id": selected_row['video_id'], "timestamp": selected_row['timestamp'], "keyframe_id": f"transcript_{selected_row['timestamp']:.2f}s"}
        return add_to_submission_list(submission_list, candidate, {"task_type": TaskType.KIS}, position)
    except Exception as e:
        gr.Error(f"L·ªói khi th√™m k·∫øt qu·∫£ transcript: {e}")
        return submission_list, format_submission_list_to_csv_string(submission_list)

def prepare_submission_for_edit(submission_list: list):
    gr.Info("ƒê√£ ƒë·ªìng b·ªô h√≥a danh s√°ch v√†o B·∫£ng ƒëi·ªÅu khi·ªÉn.")
    return format_submission_list_to_csv_string(submission_list)

def clear_submission_state_and_editor():
    gr.Info("ƒê√£ x√≥a danh s√°ch n·ªôp b√†i v√† n·ªôi dung trong b·∫£ng ƒëi·ªÅu khi·ªÉn.")
    return [], ""

def calculate_frame_number(video_id: str, time_input: str, fps_map: dict):
    if not video_id or not time_input: return "Vui l√≤ng nh·∫≠p Video ID v√† Th·ªùi gian."
    try:
        time_input_str = str(time_input).strip()
        match = re.match(r'(\d+)\s*:\s*(\d+(\.\d+)?)', time_input_str)
        if match:
            minutes, seconds = int(match.group(1)), float(match.group(2))
            timestamp = minutes * 60 + seconds
        else:
            timestamp = float(time_input_str)
        fps = fps_map.get(video_id, 30.0)
        return str(round(timestamp * fps))
    except Exception:
        return f"L·ªói: ƒê·ªãnh d·∫°ng th·ªùi gian '{time_input}' kh√¥ng h·ª£p l·ªá."

def handle_submission(submission_csv_text: str, query_id: str):
    if not submission_csv_text or not submission_csv_text.strip():
        gr.Warning("N·ªôi dung n·ªôp b√†i ƒëang tr·ªëng.")
        return None
    if not query_id.strip():
        gr.Warning("Vui l√≤ng nh·∫≠p Query ID.")
        return None
    try:
        # Check if text is valid CSV before writing
        pd.read_csv(StringIO(submission_csv_text), header=None)
        
        output_dir = "/kaggle/working/submissions"
        os.makedirs(output_dir, exist_ok=True)
        file_path = os.path.join(output_dir, f"{query_id}_submission.csv")
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(submission_csv_text.strip())
        
        gr.Success(f"ƒê√£ t·∫°o file n·ªôp b√†i th√†nh c√¥ng!")
        return file_path
    except Exception as e:
        gr.Error(f"L·ªói ƒë·ªãnh d·∫°ng CSV: {e}.")
        return None

def clear_all():
    analysis_clear_vals = clear_analysis_panel()
    transcript_clear_main_vals = ("", "", "", "T√¨m th·∫•y: 0 k·∫øt qu·∫£.", pd.DataFrame(), None)
    submission_clear_vals = ("", [])
    file_clear_vals = ("", None)
    return (
        [], "", None, "Trang 1 / 1", [], 1, # M·∫Øt Th·∫ßn
        *transcript_clear_main_vals,       # Tai Th√≠nh
        *analysis_clear_vals,              # Tr·∫°m Ph√¢n t√≠ch
        *submission_clear_vals,            # B·∫£ng ƒëi·ªÅu khi·ªÉn
        *file_clear_vals                   # Xu·∫•t File
    )